\documentclass[11pt]{article}
\usepackage{url,amsmath,setspace,amssymb,amsthm,fullpage}
\usepackage{algorithm,algorithmic}


% Scribe template modified from original created by UC Berkeley's EECS department

\newcommand{\heading}[5]{
   \renewcommand{\thepage}{#1-\arabic{page}}
   \noindent
   \begin{center}
   \framebox[\textwidth]{
     \begin{minipage}{0.9\textwidth} \onehalfspacing
       {\bf STATS 710 -- Seq. Dec. Making with mHealth Applications} \hfill #2

       {\centering \Large #5

       }\medskip

       {\it #3 \hfill #4}
     \end{minipage}
   }
   \end{center}
}

\newcommand{\scribe}[4]{\heading{#1}{#2}{Instructors:
Susan Murphy and Ambuj Tewari}{Scribe: #4}{Lecture #1: #3}}

\input{macros}

\bibliographystyle{alpha}

\begin{document}
\scribe{4}{Sep 15, 2016}{Proof the finite-time upper bound of expected regret for Upper Confidence Bound (UCB)}{Tim NeCamp}
\section{Clarifications from Lecture 3}

Where do we use the bound $0 \le d \le min_{a:\mu_a < \mu_\star} \Delta_a$?

In our proof, we had:

$\prob{A_t = a} \leq \frac{\epsilon_t}{K} + 2 x_0 e^{-x_0/5} + \frac{4}{\Delta_a^2}e^{-\Delta_a^2 x_0 / 2} 
\leq \frac{c}{d^2t} + \frac{2c}{d^2} \log{ (\frac{(t-1)d^2e}{2cK})} (\frac{2cK}{(t-1)d^2e})^{d^2 c/5}
+ \frac{4}{d^2}(\frac{2cK}{(t-1)d^2e})^{c/2}$.

The first inequality required no bound on the gap, however to obtain the second inequality we utilized two things:
\begin{itemize}
\item To eliminate $x_0$ we use: $x_0  := \frac{\sum_1^t \epsilon_i }{2K} \geq \frac{c}{d^2}\log (\frac{t d^2 e}{2cK}) $
\item To eliminate $\Delta_a$ we use: $0 \le d \le min_{a:\mu_a < \mu_\star} \Delta_a$
\end{itemize}

\section{UCB algorithm and finite time regret bound}

\subsubsection{UCB Algorithm}

The algorithm and its analysis are both from~\cite{auer2002finite}.

At time $t \leq K$, do:

Pick action $a$ when $t = a$.\\
\\
\noindent At time $t > K$, do:
\begin{enumerate}
\item $\forall a \in A$, compute $\bar R^a_t$ and $N_t(a)$. 
\item Pick action $a$ to maximize:
$\bar R_t^a + \sqrt{\frac{2\log(t)}{N_t(a)}} $
\end{enumerate}

\subsubsection{Finite time expected regret bound for UCB}

\begin{theorem}
Assume that all distributions ($D_a, \forall a$) have support in $[0,1]$. Then, under the UCB algorithm:

$\regret_T(\la_{UCB}, (D_a)_{a \in \actions}) \leq \sum\limits_{a: \mu_a < \mu_*} \frac{8\log T}{\Delta_a} + \ (1 + \frac{\pi^2}{3})(\sum\limits_{a: a \in \actions} \Delta_a)$

\end{theorem}


\section{Intuition in Theorem and Proof}

\subsection{Why is it called 'upper confidence" bound?}

We have optimism in the face of uncertainty.  We can think of a confidence interval for $\mu_a$ as $(\bar R_t^a - \sqrt{\frac{2\log(t)}{N_t(a)}} , \bar R_t^a + \sqrt{\frac{2\log(t)}{N_t(a)}} )$.  We  assume that $\mu_a$ takes the value of the upper value (optimism)  of it's confidence interval, and pick an action accordingly.

\subsection{What if distributions have support outside of $[0,1]$?}

Similar to $\epsilon$-greedy, we really only need sub-gaussian distributions.  That way we are still able to use a concentration inequality.  The expected regret bound will obviously slightly change.

\section{Proof strategy}

For the $\epsilon$-greedy algorithm, we proceeded by bounding the probability of selecting a sub-optimal action at time T.  For this proof, we will obtain the result by instead bound $\E{N_T(a)}$.  Specifically we will obtain:

$\E{N_T(a)} \leq \frac{8 \log T}{\Delta_a^2} + 1 + \frac{\pi^2}{3}$.

\section{Proof of theorem}

\begin{proof} Let $c_{t,n} := \sqrt{\frac{2\log t}{n}}$.  For arbitrary positive integer $l$ (we will choose it's value later), at time $T$, and for $a$ s.t. $\Delta_a > 0$, we have:

$N_T(a) = 1 + \sum\limits^T_{t = K + 1} \ind (A_t = a)$

$\leq l + \sum\limits^T_{t = K + 1} \ind (A_t = a \wedge N_{t-1}(a) \geq l)$

$\leq l + \sum\limits^T_{t = K + 1} \ind ([\bar R^*_{N_{t-1}^*} + c_{t-1,N_{t-1}^*} \leq \bar R^a_{N_{t-1}(a)} + c_{t-1,N_{t-1}(a)}] \wedge [N_{t-1}(a) \geq l]) $*

(*{\scriptsize You may want to use a concentration inequality here but, the inequality cannot be applied for a random time, $N_{t-1}(a)$})

$\leq l +  \sum\limits^T_{t = K + 1} \ind( \exists \  1 \leq n \leq t-1, l \leq m \leq t-1 \text{ such that } \bar R^*_{n} + c_{t-1,n} \leq \bar R^a_{m} + c_{t-1,m}   ) $

$ \leq l +  \sum\limits^T_{t = K + 1}  \sum\limits^{t-1}_{n = 1}  \sum\limits^{t-1}_{m = l} \ind (\bar R^*_{n} + c_{t-1,n} \leq \bar R^a_{m} + c_{t-1,m}  )$

$ \leq l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \ind (\bar R^*_{n} + c_{t,n} \leq \bar R^a_{m} + c_{t,m}  )$ 

Thus, $N_T(a)  \leq l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \ind (\bar R^*_{n} + c_{t,n} \leq \bar R^a_{m} + c_{t,m} )$ \ \ \ \ \ \ \ \ \  \ \ \ \ \  {\bf{(1)}}
\\
\\

\begin{lemma}\label{lem}
Let E = $\{ \bar R^*_{n} + c_{t,n} \leq \bar R^a_{m} + c_{t,m} \}$ (from last sum above), F = $\{ \bar R^*_{n} \leq \mu_* - c_{t,n} \}$,\\ G = $\{ \bar R^a_{m} \geq \mu_a + c_{t,m} \}$, H = $\{ \mu_* < \mu_a + 2c_{t,m} \}$.  Then E $\subset $ (F $\cup$ G $\cup$ H):
\end{lemma}



\begin{proof} Assume $\neg $ F $\cap \  \neg$ G $\cap \  \neg$ H then:

$ \bar R^*_{n} > \mu_* - c_{t,n}$  (from $\neg $ F)

$ \geq   \mu_a + 2c_{t,m} - c_{t,n} $	(from $\neg $ H)

$ \geq   \bar R^a_{m} - c_{t,m} + 2c_{t,m} - c_{t,n} $	(from $\neg $ G)

$ =  \bar R^a_{m} + c_{t,m} - c_{t,n} $ (from algebra).

So $\bar R^*_{n} + c_{t,n} > \bar R^a_{m} + c_{t,m}$, which shows that ($\neg $ F $\cap \  \neg$ G $\cap \  \neg$ H) $ \subset \neg $ E. \end{proof}

Note that $H$ is non-random, so we choose $l$ to make H false. Specifically, set $l = \Big \lceil \frac{8 \log T}{\Delta_a^2} \Big \rceil $.  Under this setting $H$ is false because:

$\mu_* - \mu_a - 2c_{t,m} = \mu_* - \mu_a - 2 \sqrt{\frac{2\log t}{m}} \geq  \mu_* - \mu_a - 2 \sqrt{\frac{2\log t}{l}} \geq  \mu_* - \mu_a - 2 \sqrt{\frac{2\log T}{l}}  \geq \mu_* - \mu_a - \Delta_a = 0 $.\\
\\

Thus, with $l = \Big \lceil \frac{8logT}{\Delta_a^2} \Big \rceil$, from {\bf(1)}, we obtain:

$\E{N_T(a) }  \leq l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \E{\ind (\bar R^*_{n} + c_{t,n} \leq \bar R^a_{m} + c_{t,m}  )}$
$= l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \prob{\bar R^*_{n} + c_{t,n} \leq \bar R^a_{m} + c_{t,m}  }$

$\leq  l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \Big[ \prob{\bar R^*_{n} \leq \mu_* - c_{t,n} } + \prob{\bar R^a_{m} \geq \mu_a + c_{t,m} }  + \prob{ \mu_* < \mu_a + 2c_{t,m}  }\Big] $ \ \ {\small by Lemma \ref{lem}}

$=  l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \Big[ \prob{\bar R^*_{n} \leq \mu_* - c_{t,n} } + \prob{\bar R^a_{m} \geq \mu_a + c_{t,m} }  \Big] $ \ \ \ \ {H has probability 0}

$\leq  l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \Big[ e^{-2nc^2_{t,n}} + e^{-2mc^2_{t,m}}   \Big] $ \ \ \ \ {\small Hoeffding-Azuma}

$\leq  l +  \sum\limits^T_{t = 1}  \sum\limits^{t}_{n = 1}  \sum\limits^{t}_{m = l} \Big[ \frac{1}{t^4} + \frac{1}{t^4}   \Big] $  \ \ \ \ \ {\small definition of $c_{t,n}$}

$\leq l + \sum\limits^T_{t = 1} \frac{2t^2}{t^4}$

$\leq l + \sum\limits^\infty_{t = 1} \frac{2}{t^2}$

$= l + \frac{\pi^2}{3}$ \ \ \ \ \  \ \ {\small because $\sum\limits^\infty_{t = 1} \frac{1}{t^2} = \frac{\pi^2}{6}$}

$\leq \frac{8 \log T}{\Delta_a^2} + 1 + \frac{\pi^2}{3}$  \ \ \ \  \ \ {\small using $l = \Big \lceil \frac{8logT}{\Delta_a^2} \Big \rceil $} \\

Thus, our regret at time T is:

$\regret_T(\la, (D_a)_{a \in \actions}) =  \sum\limits_{a: a \in \actions} \Delta_a \E{N_T(a)} \leq $
$\sum\limits_{a: a \in \actions} \Delta_a(\frac{8 \log T}{\Delta_a^2} + 1 + \frac{\pi^2}{3}) $

$ = \sum\limits_{a: a \in \actions} \frac{8 \log T}{\Delta_a} + \ (1 + \frac{\pi^2}{3})(\sum\limits_{a: a \in \actions} \Delta_a)$  \end{proof}

\section{Discussion on only having concern for expected regret}

There is some concern about only focusing only on the expected regret, especially in a mobile health setting. For example, though, on average, our algorithm performs well (i.e. the expected regret is small) what if the variance of the regret is large.  This might mean that it is not unlikely that there will be a few people for which the regret is extremely large.  This large regret for those few people may be inexcusable/unethical, especially in a health setting.




\bibliography{stats710}
\end{document}

